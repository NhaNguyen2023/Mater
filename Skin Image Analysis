library(keras)
library(EBImage) #not able to install
library(ijtiff) #video, animation
library(magick) #install.packages()
library(dplyr)
library(stringr)
library(pbapply)
install_keras()

getwd()
setwd("C:/Users/nhanguyen/Downloads/R/Skin/Data")
#setwd(paste0(getwd(),"/."))

# Get the list of all images in a specific folder
allFiles <- list.files(path = "C:/Users/nhanguyen/Downloads/R/Skin/Data/resized training images", pattern = ".jpg", full.names = T)

# checking if a file or folder exists
#file.exists("")
#file_access(), file_exists(), dir_exists(), link_exists(): Query for existence and access permissions

# directory creation
#ifelse(!dir.exists("Images"), dir.create("Images"), "Folder exists already")
#list.files(recursive = TRUE) #identify all files w/in the subfolders

# blank file
#file.create("new_text.txt")
#file.create("new_word.docx")
#file.create("new_csv.csv")

#1 Data
# Get the files from a browsed folder
#list.files(path = choose.dir()) 
#onlFiles <- list.files(path = choose.dir())

# Get the dataframe with info
allInfo <- image_info(image_read(allFiles)) # takes a lot of time and space to read

# Attach the file names
allInfo$fileName = list.files(path = "C:/Users/nhanguyen/Downloads/R/Skin/Data/resized training images", pattern = ".jpg")

#Save
write.csv(allInfo, "allImageInfo.csv")

#Read the truth
allResult <- read.csv("ISIC_2019_Training_GroundTruth1.csv")
varSize <- function(data, column_name) {
  size <- sum(data[column_name])
  return(size)
}
mel <- varSize(allResult, "MEL")
mel
allResult$outcome <- ifelse(allResult$MEL==1, "MEL", ifelse(allResult$NV==1, "NV", ifelse(allResult$BCC==1, "BCC", ifelse(allResult$AK==1, "AK", ifelse(allResult$BKL==1, "BKL", ifelse(allResult$DF==1, "DF", ifelse(allResult$VASC==1, "VASC", ifelse(allResult$SCC==1, "SCC", NA))))))))

#sample <- sample(c(TRUE,FALSE), nrow(allInfo), replace=TRUE, prob=c(0.7,0.3))
#train <- allInfo[sample, ]
#validation <- allInfo[!sample, ]
#set.seed(13)
#allFilesIndex <- data.frame(createDataPartition(allFiles, p=.7, list=FALSE, times=10))
#head(allFilesIndex)

colnames(allResult)[1] <- "fileName"
head(allResult)
skin_img <- merge(x=allInfo, y=allResult, by="fileName", all=TRUE)

folder_list <- list.files("C:/Users/nhanguyen/Downloads/R/Skin/Data/resized training images/")
folder_list

folder_path <- paste0("C:/Users/nhanguyen/Downloads/R/Skin/Data/resized training images/", folder_list, "/")
folder_path
# Get file name
file_name <- map(folder_path, 
                 function(x) paste0(x, list.files(x))
                 ) %>% 
  unlist() #map function in package purrr

head(file_name)
tail(file_name)
length(file_name)

# Randomly select image
set.seed(99)
sample_img <- sample(file_name, 6)

# Load image into R
img <- map(sample_img, load.image) #library(imager)

# Plot image
par(mfrow = c(2, 3)) # Create 2 x 3 image grid
map(img, plot)

#2 Data Preprocessing
#2.1 Data Augmentation
# Desired height and width of images
target_size <- c(255, 255)

# Batch size for training the model
batch_size <- 32

# Image Generator
train_data_gen <- image_data_generator(rescale = 1/255, # Scaling pixel value
                                       horizontal_flip = T, # Flip image horizontally
                                       vertical_flip = T, # Flip image vertically 
                                       rotation_range = 45, # Rotate image from 0 to 45 degrees
                                       zoom_range = 0.25, # Zoom in or zoom out range
                                       validation_split = 0.2 # 20% data as validation data
                                       )
# Training Dataset
train_image_array_gen <- flow_images_from_directory(directory = "Data/resized training images/", # Folder of the data
                                                    target_size = target_size, # target of the image dimension (64 x 64)  
                                                    color_mode = "rgb", # use RGB color
                                                    batch_size = batch_size , 
                                                    seed = 123,  # set random seed
                                                    subset = "training", # declare that this is for training data
                                                    generator = train_data_gen
                                                    )

# Validation Dataset
val_image_array_gen <- flow_images_from_directory(directory = "Data/resized training images/",
                                                  target_size = target_size, 
                                                  color_mode = "rgb", 
                                                  batch_size = batch_size ,
                                                  seed = 123,
                                                  subset = "validation", # declare that this is the validation data
                                                  generator = train_data_gen
                                                  )

# Number of training samples
train_samples <- train_image_array_gen$n

# Number of validation samples
valid_samples <- val_image_array_gen$n

# Number of target classes/categories
output_n <- n_distinct(train_image_array_gen$classes)

# Get the class proportion
table("\nFrequency" = factor(train_image_array_gen$classes)
      ) %>% 
  prop.table()

#3 CNN
#3.1 Model Architecture
# input shape of the image
c(target_size, 3)

# Set Initial Random Weight
tensorflow::tf$random$set_seed(123)

model <- keras_model_sequential(name = "simple_model") %>% 
  
  # Convolution Layer
  layer_conv_2d(filters = 16,
                kernel_size = c(3,3),
                padding = "same",
                activation = "relu",
                input_shape = c(target_size, 3) 
                ) %>% 

  # Max Pooling Layer
  layer_max_pooling_2d(pool_size = c(2,2)) %>% 
  
  # Flattening Layer
  layer_flatten() %>% 
  
  # Dense Layer
  layer_dense(units = 16,
              activation = "relu") %>% 
  
  # Output Layer
  layer_dense(units = output_n,
              activation = "softmax",
              name = "Output")
  
model

#3.2 Model Fitting
model %>% 
  compile(
    loss = "categorical_crossentropy",
    optimizer = optimizer_adam(lr = 0.01),
    metrics = "accuracy"
  )

# Fit data into model
history <- model %>% 
  fit(
  # training data
  train_image_array_gen,

  # training epochs
  steps_per_epoch = as.integer(train_samples / batch_size), 
  epochs = 30, 
  
  # validation data
  validation_data = val_image_array_gen,
  validation_steps = as.integer(valid_samples / batch_size)
)

plot(history)

#3.3 Model Evaluation
val_data <- data.frame(file_name = paste0("Data/resized training images/", val_image_array_gen$fileName)) %>% 
  mutate(class = str_extract(file_name, "DF|NV|MEL|BCC|BKL|AK|SCC|VASC"))

head(val_data, 10)

# Function to convert image to array
image_prep <- function(x) {
  arrays <- lapply(x, function(path) {
    img <- image_load(path, target_size = target_size, 
                      grayscale = F # Set FALSE if image is RGB
                      )
    
    x <- image_to_array(img)
    x <- array_reshape(x, c(1, dim(x)))
    x <- x/255 # rescale image pixel
  })
  do.call(abind::abind, c(arrays, list(along = 1)))
}

test_x <- image_prep(val_data$file_name)

# Check dimension of testing data set
dim(test_x)

pred_test <- predict_classes(model, test_x) 
head(pred_test, 10)

# Convert encoding to label
decode <- function(x){
  case_when(x == 0 ~ "DF",
            x == 1 ~ "NV",
            x == 2 ~ "MEL",
            x == 3 ~ "BCC",
            x == 4 ~ "BKL",
            x == 5 ~ "AK",
            x == 6 ~ "SCC",
            x == 7 ~ "VASC"
            )
}

pred_test <- sapply(pred_test, decode) 

head(pred_test, 10)

confusionMatrix(as.factor(pred_test), 
                as.factor(val_data$outcome)
                )

#4 Tuning the Model
#4.1 Model Architecture
model
# Design new model
tensorflow::tf$random$set_seed(123)

model_big <- keras_model_sequential() %>% 
  
  # First convolutional layer
  layer_conv_2d(filters = 32,
                kernel_size = c(5,5), # 5 x 5 filters
                padding = "same",
                activation = "relu",
                input_shape = c(target_size, 3)
                ) %>% 
  
  # Second convolutional layer
  layer_conv_2d(filters = 32,
                kernel_size = c(3,3), # 3 x 3 filters
                padding = "same",
                activation = "relu"
                ) %>% 
  
  # Max pooling layer
  layer_max_pooling_2d(pool_size = c(2,2)) %>% 
  
  # Third convolutional layer
  layer_conv_2d(filters = 64,
                kernel_size = c(3,3),
                padding = "same",
                activation = "relu"
                ) %>% 

  # Max pooling layer
  layer_max_pooling_2d(pool_size = c(2,2)) %>% 
  
  # Fourth convolutional layer
  layer_conv_2d(filters = 128,
                kernel_size = c(3,3),
                padding = "same",
                activation = "relu"
                ) %>% 
  
  # Max pooling layer
  layer_max_pooling_2d(pool_size = c(2,2)) %>% 

  # Fifth convolutional layer
  layer_conv_2d(filters = 256,
                kernel_size = c(3,3),
                padding = "same",
                activation = "relu"
                ) %>% 
  
  # Max pooling layer
  layer_max_pooling_2d(pool_size = c(2,2)) %>% 
  
  # Flattening layer
  layer_flatten() %>% 
  
  # Dense layer
  layer_dense(units = 64,
              activation = "relu") %>% 
  
  # Output layer
  layer_dense(name = "Output",
              units = 3, 
              activation = "softmax")

model_big

#4.2 Model Fitting
# train the data with 50 epochs (more epochs). We will also lower the learning rate from 0.01 to 0.001
model_big %>% 
  compile(
    loss = "categorical_crossentropy",
    optimizer = optimizer_adam(lr = 0.001),
    metrics = "accuracy"
  )

history <- model %>% 
  fit_generator(
  # training data
  train_image_array_gen,
  
  # epochs
  steps_per_epoch = as.integer(train_samples / batch_size), 
  epochs = 50, 
  
  # validation data
  validation_data = val_image_array_gen,
  validation_steps = as.integer(valid_samples / batch_size),
  
  # print progress but don't create graphic
  verbose = 1,
  view_metrics = 0
)

plot(history)

#4.3 Model Evaluation
pred_test <- predict_classes(model_big, test_x) 
head(pred_test, 10)
# Convert encoding to label
decode <- function(x){
  case_when(x == 0 ~ "DF",
            x == 1 ~ "NV",
            x == 2 ~ "MEL",
            x == 3 ~ "BCC",
            x == 4 ~ "BKL",
            x == 5 ~ "AK",
            x == 6 ~ "SCC",
            x == 7 ~ "VASC"
            )
}

pred_test <- sapply(pred_test, decode) 
head(pred_test, 10)

confusionMatrix(as.factor(pred_test), 
                as.factor(val_data$outcome)
                )

#5 Predict data in Testing dataset
df_test  <- read.csv(".csv")
head(df_test, 10)

# convert image into 2D array
test_x <- image_prep(df_test$file_name)
# Check dimension of testing data set
dim(test_x)

pred_test <- predict_classes(model_big, test_x) 
head(pred_test, 10)

# Convert encoding to label
decode <- function(x){
  case_when(x == 0 ~ "cat",
            x == 1 ~ "dog",
            x == 2 ~ "panda"
            )
}

pred_test <- sapply(pred_test, decode) 
head(pred_test, 10)

confusionMatrix(as.factor(pred_test), 
                as.factor(df_test$class)
                )



train_x, valid_x, train_y, valid_y <- train_test_split(skin_img, Y, test_size=0.3, random_state=230)
#inspect the shape of training and testing
print(train_x.shape)
print(train_y.shape)
print(valid_x.shape)
print(valid_y.shape)

library(DMwR)
mel <- SMOTE(MEL ~ ., skin_img, perc.over = 

# Set image size
width <- 50
height <- 50
extract_feature <- function(dir_path, width, height, labelsExist = T) {
img_size <- width * height
## List images in path
images_names <- list.files(dir_path)
if(labelsExist){
## Select only cats or dogs images
catdog <- str_extract(images_names, "^(cat|dog)")
# Set cat == 0 and dog == 1
key <- c("cat" = 0, "dog" = 1)
y <- key[catdog]
}
print(paste("Start processing", length(images_names), "images"))
## This function will resize an image, turn it into greyscale
feature_list <- pblapply(images_names, function(imgname) {
## Read image
img <- readImage(file.path(dir_path, imgname))
## Resize image
img_resized <- resize(img, w = width, h = height)
## Set to grayscale (normalized to max)
grayimg <- channel(img_resized, "gray")
## Get the image as a matrix
img_matrix <- grayimg@.Data
## Coerce to a vector (row-wise)
img_vector <- as.vector(t(img_matrix))
return(img_vector)
})
## bind the list of vector into matrix
feature_matrix <- do.call(rbind, feature_list)
feature_matrix <- as.data.frame(feature_matrix)
## Set names
names(feature_matrix) <- paste0("pixel", c(1:img_size))
if(labelsExist){
return(list(X = feature_matrix, y = y))
}else{
return(feature_matrix)
}
}

# Takes approx. 15min
trainData <- extract_feature("train/", width, height)
# Takes slightly less
testData <- extract_feature("test1/", width, height, labelsExist = F)

# Check processing on second cat
par(mar = rep(0, 4))
testCat <- t(matrix(as.numeric(trainData$X[2,]),
nrow = width, ncol = height, T))
image(t(apply(testCat, 2, rev)), col = gray.colors(12),
axes = F)
# Save
save(trainData, testData, file = "catdogData.RData")

# Fix structure for 2d CNN
train_array %
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 1, activation = "sigmoid")
summary(model)
model %>% compile(
loss = 'binary_crossentropy',
optimizer = "adam",
metrics = c('accuracy')
)
history % fit(
x = train_array, y = as.numeric(trainData$y),
epochs = 30, batch_size = 100,
validation_split = 0.2
)
plot(history)

# Compute probabilities and predictions on test set
predictions <-  predict_classes(model, test_array)
probabilities <- predict_proba(model, test_array)
# Visual inspection of 32 cases
set.seed(100)
random <- sample(1:nrow(testData), 32)
preds <- predictions[random,]
probs <- as.vector(round(probabilities[random,], 2))
par(mfrow = c(4, 8), mar = rep(0, 4))
for(i in 1:length(random)){
image(t(apply(test_array[random[i],,,], 2, rev)),
col = gray.colors(12), axes = F)
legend("topright", legend = ifelse(preds[i] == 0, "Cat", "Dog"),
text.col = ifelse(preds[i] == 0, 2, 4), bty = "n", text.font = 2)
legend("topleft", legend = probs[i], bty = "n", col = "white")
}
# Save model
save(model, file = "CNNmodel.RData")

model.fit(train_x, train_y, epochs = 5, batch_size = 3546)
preds <- model.evaludate(test_x, test_y)
print ("Loss = " + str(preds[0]))
print ("Test Accuracy = " + str(preds[1]))
